{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cats and Dogs - Intro to Keras and OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages Part 1/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Code Reference:\n",
    "https://towardsdatascience.com/how-to-build-a-weapon-detection-system-using-keras-and-opencv-67b19234e3dd\n",
    "'''\n",
    "\n",
    "from typing_extensions import runtime\n",
    "import pandas as pd \n",
    "import os\n",
    "import numpy as np \n",
    "import cv2\n",
    "from keras.preprocessing import image \n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from skimage.segmentation import mark_boundaries \n",
    "import argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customizable Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Paths to folders containing data\n",
    "'''\n",
    "obj1_folder_relative_path = \"cats-folder/\"\n",
    "obj2_folder_relative_path = \"dogs-folder/\"\n",
    "images_with_noobj_relative_path = \"none-imgs-folder/\"\n",
    "path_to_model_weights = \"foldername/ModelWeights.h5\"\n",
    "path_to_test_folder = \"test-imgs-folder/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_value(path, dim): \n",
    "    img = image.load_img(path, target_size = dim)\n",
    "    img = image.img_to_array(img)\n",
    "    return img/255\n",
    "\n",
    "def get_img_array(img_paths, dim): \n",
    "    final_array = []\n",
    "    from tqdm import tqdm\n",
    "    for path in tqdm(img_paths):\n",
    "        img = get_image_value(path, dim)\n",
    "        final_array.append(img)\n",
    "    final_array = np.array(final_array)  \n",
    "    return final_array\n",
    "\n",
    "def get_tts():\n",
    "    '''This function will create a train test split'''  \n",
    "    DIM =  (150,150) \n",
    "    np.random.seed(10)\n",
    "    # Object 1      \n",
    "    obj1_paths = [f'{obj1_folder_relative_path}{i}' for i in os.listdir(obj1_folder_relative_path)] \n",
    "    obj1_labels = [1 for i in range(len(obj1_paths))]\n",
    "    # Object 2\n",
    "    obj2_paths = [f'{obj2_folder_relative_path}{i}' for i in os.listdir(obj2_folder_relative_path)] \n",
    "    obj2_labels = [2 for i in range(len(obj2_paths))]    \n",
    "    # No Objects\n",
    "    noobj_paths = [f'{images_with_noobj_relative_path}{i}' for i in os.listdir(images_with_noobj_relative_path)]\n",
    "    np.random.shuffle(noobj_paths)\n",
    "    noobj_paths = noobj_paths[:len(obj1_paths)- 500]\n",
    "    noobj_labels = [0 for i in range(len(noobj_paths))]\n",
    "\n",
    "    np.random.shuffle(obj1_paths)\n",
    "    obj1_paths = obj1_paths[:len(obj2_paths)+150]\n",
    "    noobj_paths = noobj_paths[:len(obj2_paths)+150]\n",
    "\n",
    "    obj1_labels = [1 for i in range(len(obj1_paths))]\n",
    "    obj2_labels = [2 for i in range(len(obj2_paths))]\n",
    "    noobj_labels = [0 for i in range(len(noobj_paths))]\n",
    "    paths = obj1_paths + obj2_paths + noobj_paths\n",
    "    labels = obj1_labels + obj2_labels + noobj_labels\n",
    "    x_train, x_test, y_train, y_test = train_test_split(paths, labels, stratify = labels, train_size = .90, random_state = 10)\n",
    "\n",
    "    new_x_train = get_img_array(x_train, DIM)\n",
    "    new_x_test = get_img_array(x_test, DIM)\n",
    "    \n",
    "    print('Train Value Counts')\n",
    "    print(pd.Series(y_train).value_counts())\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    print('Test Value Counts')\n",
    "    print(pd.Series(y_test).value_counts())\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    print('X Train Shape')\n",
    "    print(new_x_train.shape)\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    print('X Test Shape')\n",
    "    print(new_x_test.shape)\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    y_test = to_categorical(y_test)\n",
    "    y_train = to_categorical(y_train)\n",
    "    tts = (new_x_train, new_x_test, y_train, y_test)\n",
    "    return tts\n",
    "\n",
    "def test():\n",
    "    print(\"running...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep Data - Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = get_tts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages Part 2/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, AveragePooling2D, Dense, Dropout, Flatten \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras import regularizers\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conv_model(dim = (150,150, 3)):\n",
    "    '''This function will create and compile a CNN given the input dimension'''\n",
    "    inp_shape = dim\n",
    "    act = 'relu'\n",
    "    drop = .25\n",
    "    kernal_reg = regularizers.l1(.001)\n",
    "    optimizer = Adam(lr = .0001)    \n",
    "    model = Sequential() \n",
    "    model.add(Conv2D(64, kernel_size=(3,3),activation=act, input_shape = inp_shape, \n",
    "                     kernel_regularizer = kernal_reg,\n",
    "                     kernel_initializer = 'he_uniform',  padding = 'same', name = 'Input_Layer'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),  strides = (3,3)))\n",
    "    model.add(Conv2D(64, (3, 3), activation=act, kernel_regularizer = kernal_reg, \n",
    "                     kernel_initializer = 'he_uniform',padding = 'same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides = (3,3))) \n",
    "    model.add(Conv2D(128, (3, 3), activation=act, kernel_regularizer = kernal_reg, \n",
    "                     kernel_initializer = 'he_uniform',padding = 'same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation=act, kernel_regularizer = kernal_reg, \n",
    "                     kernel_initializer = 'he_uniform',padding = 'same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides = (3,3)))  \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(drop))\n",
    "    model.add(Dense(3, activation='softmax', name = 'Output_Layer'))\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prevents overfitting and saves models every time the validation loss improves\n",
    "early_stopping = EarlyStopping(monitor='val_loss', verbose = 1, patience=10, min_delta = .00075)\n",
    "model_checkpoint = ModelCheckpoint(path_to_model_weights, verbose = 1, save_best_only=True,\n",
    "                                  monitor = 'val_loss')\n",
    "lr_plat = ReduceLROnPlateau(patience = 2, mode = 'min')\n",
    "epochs = 1000\n",
    "batch_size = 32\n",
    "model = get_conv_model()\n",
    "model_history = model.fit(x_train, y_train, batch_size = batch_size,\n",
    "            epochs = epochs, \n",
    "     callbacks = [early_stopping, model_checkpoint, lr_plat], validation_data = (x_test, y_test), verbose= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ...Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression(boxes, overlapThresh= .5):\n",
    "    '''This image was taken from PyImageSearch... again cannot thank that guy enough'''\n",
    "    # if there are no boxes, return an empty list\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "    # if the bounding boxes integers, convert them to floats --\n",
    "    # this is important since we'll be doing a bunch of divisions\n",
    "    if boxes.dtype.kind == \"i\":\n",
    "        boxes = boxes.astype(\"float\")\n",
    "    # initialize the list of picked indexes\t\n",
    "    pick = []\n",
    "    # grab the coordinates of the bounding boxes\n",
    "    x1, y1, x2, y2 = boxes[:,0], boxes[:,1], boxes[:,2], boxes[:,3]    \n",
    "    # compute the area of the bounding boxes and sort the bounding\n",
    "    # boxes by the bottom-right y-coordinate of the bounding box\n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    idxs = np.argsort(y2)\n",
    "    # keep looping while some indexes still remain in the indexes\n",
    "    # list\n",
    "    while len(idxs) > 0:\n",
    "        # grab the last index in the indexes list and add the\n",
    "        # index value to the list of picked indexes\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    "        # find the largest (x, y) coordinates for the start of\n",
    "        # the bounding box and the smallest (x, y) coordinates\n",
    "        # for the end of the bounding box\n",
    "        xx1, yy1, xx2, yy2 = np.maximum(x1[i], x1[idxs[:last]]), np.maximum(y1[i], y1[idxs[:last]]), np.minimum(x2[i], x2[idxs[:last]]), np.minimum(y2[i], y2[idxs[:last]])\n",
    "        # compute the width and height of the bounding box\n",
    "        w, h = np.maximum(0, xx2 - xx1 + 1), np.maximum(0, yy2 - yy1 + 1)\n",
    "        # compute the ratio of overlap\n",
    "        overlap = (w * h) / area[idxs[:last]]\n",
    "        # delete all indexes from the index list that have\n",
    "        idxs = np.delete(idxs, np.concatenate(([last],\n",
    "            np.where(overlap > overlapThresh)[0])))\n",
    "    # return only the bounding boxes that were picked using the\n",
    "    # integer data type\n",
    "    return pick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw Box on Images for Identifying Obj Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_prediction_bounding_box(path, model, dim):\n",
    "    '''This function will create a bounding box over what it believes is a weapon given the image path, dimensions, and model used to detect the weapon.  Dimensions can be found within the Var.py file.  This function is still being used as I need to apply non-max suppresion to create only one bounding box'''\n",
    "    img = get_image_value(path, dim)   \n",
    "    img = img.reshape(1, img.shape[0], img.shape[1], 3)\n",
    "    pred = model.predict(img)[0]\n",
    "    category_dict = {0: 'No Weapon', 1: 'Handgun', 2: 'Rifle'}\n",
    "    cat_index = np.argmax(pred)\n",
    "    cat = category_dict[cat_index]\n",
    "    print(f'{path}\\t\\tPrediction: {cat}\\t{int(pred.max()*100)}% Confident')\n",
    "\n",
    "    #speed up cv2\n",
    "    cv2.setUseOptimized(True)\n",
    "    cv2.setNumThreads(10) #change depending on your computer\n",
    "    img = cv2.imread(path)\n",
    "    clone = img.copy() \n",
    "    clone2 = img.copy()\n",
    "    ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
    "    ss.setBaseImage(img)\n",
    "    ss.switchToSelectiveSearchFast()\n",
    "\n",
    "    rects = ss.process() \n",
    "    windows = []\n",
    "    locations = []\n",
    "    print(f'Creating Bounding Boxes for {path}')\n",
    "    for x, y, w,h in rects[:1001]: \n",
    "        startx, starty, endx, endy = x, y, x+w, y+h \n",
    "        roi = img[starty:endy, startx:endx]\n",
    "        roi = cv2.resize(roi, dsize =dim, interpolation = cv2.INTER_CUBIC)\n",
    "        windows.append(roi)\n",
    "        locations.append((startx, starty, endx, endy))\n",
    "    windows = np.array(windows)\n",
    "    windows = windows.reshape(windows.shape[0], windows.shape[1], windows.shape[2], 3)\n",
    "    windows = np.array(windows)\n",
    "    locations = np.array(locations)\n",
    "    predictions = model.predict(windows)\n",
    "    nms = non_max_suppression(locations)\n",
    "    bounding_cnt = 0\n",
    "    for idx in nms:\n",
    "        if np.argmax(predictions[idx]) != cat_index: \n",
    "            continue\n",
    "        startx, starty, endx, endy = locations[idx]\n",
    "        cv2.rectangle(clone, (startx, starty), (endx, endy), (0,0,255), 2)\n",
    "        text = f'{category_dict[np.argmax(predictions[idx])]}: {int(predictions[idx].max()*100)}%'\n",
    "        cv2.putText(clone, text, (startx, starty+15), cv2.FONT_HERSHEY_SIMPLEX, .5, (0,255,0),2)\n",
    "        bounding_cnt += 1\n",
    "\n",
    "    if bounding_cnt == 0: \n",
    "        pred_idx= [idx for idx, i in enumerate(predictions) if np.argmax(i) == cat_index]\n",
    "        cat_locations = np.array([locations[i] for i in pred_idx])\n",
    "        nms = non_max_suppression(cat_locations)\n",
    "        if len(nms)==0:\n",
    "            cat_predictions = predictions[:,cat_index]\n",
    "            pred_max_idx = np.argmax(cat_predictions)\n",
    "            pred_max = cat_predictions[pred_max_idx]\n",
    "            pred_max_window = locations[pred_max_idx]\n",
    "            startx, starty, endx, endy = pred_max_window\n",
    "            cv2.rectangle(clone, (startx, starty), (endx, endy),  (0,0,255),2)\n",
    "            text = f'{category_dict[cat_index]}: {int(pred_max*100)}%'\n",
    "            cv2.putText(clone, text, (startx, starty+15), cv2.FONT_HERSHEY_SIMPLEX, .5, (0,255,0),2)\n",
    "        for idx in nms: \n",
    "            startx, starty, endx, endy = cat_locations[idx]\n",
    "            cv2.rectangle(clone, (startx, starty), (endx, endy), (0,0,255), 2)\n",
    "            text = f'{category_dict[np.argmax(predictions[pred_idx[idx]])]}: {int(predictions[pred_idx[idx]].max()*100)}%'\n",
    "            cv2.putText(clone, text, (startx, starty+15), cv2.FONT_HERSHEY_SIMPLEX, .5, (0,255,0),2)        \n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    cv2.imshow(f'Test', np.hstack([clone, clone2]))\n",
    "    cv2.waitKey(0)\n",
    "    ss.clear()\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Tests'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26611/3046389523.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Tests'\u001b[0m \u001b[0;31m#folder where you will put your images to test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_folder\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'ipynb_checkpoints'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{test_folder}/{i}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_img_prediction_bounding_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormal_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Tests'"
     ]
    }
   ],
   "source": [
    "#NORMAL MODEL\n",
    "\n",
    "dim = (150, 150, 3)    \n",
    "normal_model = get_conv_model(path_to_model_weights)\n",
    "normal_model.load_weights() \n",
    "predictions = []\n",
    "for idx, i in enumerate([i for i in os.listdir(path_to_test_folder) if i != 'ipynb_checkpoints']):\n",
    "    img_path = f'{path_to_test_folder}/{i}'\n",
    "    pred = get_img_prediction_bounding_box(img_path, normal_model, dim = (150,150))\n",
    "    predictions.append(pred)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
